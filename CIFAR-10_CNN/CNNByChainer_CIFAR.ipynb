{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNNByChainer_CIFAR.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Wkv-hXTebP0I",
        "colab_type": "code",
        "outputId": "86a7794b-525e-4fc6-c58d-83976414dad0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "cell_type": "code",
      "source": [
        "# import\n",
        "%matplotlib inline\n",
        "# cupyのインストール\n",
        "!curl https://colab.chainer.org/install | sh -\n",
        "!pip install chutil\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import chainer\n",
        "import chutil\n",
        "\n",
        "import chainer.functions as F\n",
        "import chainer.links as L\n",
        "from chainer import Chain\n",
        "import chainer.optimizers as optimizers\n",
        "\n",
        "from chainer.datasets import get_cifar10\n",
        "from chainer import optimizers, training\n",
        "from chainer.training import extensions\n",
        "\n",
        "# データセットがダウンロード済みでなければ、ダウンロードも行う\n",
        "train, test = get_cifar10()\n",
        "train, validation = chainer.datasets.split_dataset_random(train, 40000, seed=0)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  1379  100  1379    0     0   1657      0 --:--:-- --:--:-- --:--:--  1655\n",
            "+ apt -y -q install cuda-libraries-dev-9-2\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "cuda-libraries-dev-9-2 is already the newest version (9.2.148-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 8 not upgraded.\n",
            "+ pip install -q cupy-cuda92  chainer \n",
            "+ set +ex\n",
            "Installation succeeded!\n",
            "Collecting chutil\n",
            "  Downloading https://files.pythonhosted.org/packages/74/d3/e761e43572a1bc53ab787a11b227b9ccc0e857cdb531805fb12e4e15707a/chutil-0.1.4-py3-none-any.whl\n",
            "Installing collected packages: chutil\n",
            "Successfully installed chutil-0.1.4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz...\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "8YivoH3AbP0V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class MyConvNet(Chain):\n",
        "    def __init__(self):\n",
        "        super(MyConvNet, self).__init__()\n",
        "        with self.init_scope():\n",
        "            # 畳み込み層の定義\n",
        "            # in_channels:Noneを指定しても動的にメモリ確保するので問題なく動作する\n",
        "            # out_channels:出力する配列のチャンネル数\n",
        "            # ksize:フィルタのサイズ（平行移動するフィルターの長さを指定）\n",
        "            # stride:入力データに対してstride分フィルターを適用していくパラメータを指定\n",
        "            # pad:イメージは画像データの周りにpadのサイズ分だけ空白を用意してそこに対してもフィルターを適用するようなイメージ\n",
        "            # dilate:今回の実装では設定していないが、飛び飛びにフィルターを適用するパラメータ\n",
        "            self.conv1 = L.Convolution2D(\n",
        "                in_channels=None, out_channels=32, ksize=3, stride=1, pad=1)\n",
        "            # 畳み込み層の定義２層目\n",
        "            self.conv2 = L.Convolution2D(\n",
        "                in_channels=None, out_channels=64, ksize=3, stride=1, pad=1)\n",
        "            # 畳み込み層の定義３層目\n",
        "            self.conv3 = L.Convolution2D(\n",
        "                in_channels=None, out_channels=128, ksize=3, stride=1, pad=1)\n",
        "            self.conv4 = L.Convolution2D(\n",
        "                in_channels=None, out_channels=256, ksize=3, stride=1, pad=1)\n",
        "            self.conv5 = L.Convolution2D(\n",
        "                in_channels=None, out_channels=256, ksize=3, stride=1, pad=1)\n",
        "            self.fc6 = L.Linear(None, 1000)\n",
        "            self.fc7 = L.Linear(None, 10)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        h = F.relu(self.conv1(x.reshape((-1, 3, 32, 32))))\n",
        "        h = F.max_pooling_2d(h, ksize=2, stride=2)\n",
        "        h = F.relu(self.conv2(h))\n",
        "        h = F.max_pooling_2d(h, ksize=2, stride=2)\n",
        "        h = F.relu(self.conv3(h))\n",
        "        h = F.max_pooling_2d(h, ksize=2, stride=2)\n",
        "        h = F.relu(self.conv4(h))\n",
        "        h = F.relu(self.conv5(h))\n",
        "        h = F.relu(self.fc6(h))\n",
        "        return self.fc7(h)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6DbJ-Dy_bP0Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def  train_and_validate(\n",
        "        model, optimizer, train, validation, n_epoch, batchsize, device=0):\n",
        "    \n",
        "    # 1. deviceがgpuであれば、gpuにモデルのデータを転送する\n",
        "    if device >= 0:\n",
        "        model.to_gpu(device)\n",
        "        \n",
        "    # 2. Optimizerを設定する\n",
        "    optimizer.setup(model)\n",
        "    \n",
        "    # 3. DatasetからIteratorを作成する\n",
        "    train_iter = chainer.iterators.SerialIterator(train, batchsize)\n",
        "    validation_iter = chainer.iterators.SerialIterator(\n",
        "        validation, batchsize, repeat=False, shuffle=False)\n",
        "    \n",
        "    # 4. Updater・Trainerを作成する\n",
        "    updater = training.StandardUpdater(train_iter, optimizer, device=device)\n",
        "    trainer = chainer.training.Trainer(updater, (n_epoch, 'epoch'), out='out')\n",
        "    \n",
        "    # 5. Trainerの機能を拡張する\n",
        "    trainer.extend(extensions.LogReport())\n",
        "    trainer.extend(extensions.Evaluator(validation_iter, model, device=device), name='val')\n",
        "    trainer.extend(extensions.PrintReport(\n",
        "        ['epoch', 'main/loss', 'main/accuracy', 'val/main/loss', 'val/main/accuracy', 'elapsed_time']))\n",
        "    trainer.extend(extensions.PlotReport(\n",
        "        ['main/loss', 'val/main/loss'],x_key='epoch', file_name='loss.png'))\n",
        "    trainer.extend(extensions.PlotReport(\n",
        "        ['main/accuracy', 'val/main/accuracy'], x_key='epoch', file_name='accuracy.png'))\n",
        "    trainer.extend(extensions.dump_graph('main/loss'))\n",
        "    \n",
        "    # 6. 訓練を開始する\n",
        "    trainer.run()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oXXiOds3rqxy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# test 結果計算\n",
        "def show_test_performance(model, test, batchsize, device=0):\n",
        "    if device >= 0:\n",
        "        model.to_gpu()\n",
        "        \n",
        "    test_iter = chainer.iterators.SerialIterator(\n",
        "        test, batchsize, repeat=False, shuffle=False\n",
        "    )\n",
        "    test_evaluator = extensions.Evaluator(test_iter, model, device=device)\n",
        "    results = test_evaluator()\n",
        "    print(\"Test accuracy:\", results[\"main/accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hLJjQrcMbP0a",
        "colab_type": "code",
        "outputId": "d949592e-5784-43ca-9b6e-e908bd6db3f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        }
      },
      "cell_type": "code",
      "source": [
        "n_epoch = 40\n",
        "batchsize = 128\n",
        "\n",
        "model = MyConvNet()\n",
        "classifier_model = L.Classifier(model)\n",
        "optimizer = optimizers.Adam()\n",
        "train_and_validate(\n",
        "    classifier_model, optimizer, train, validation, n_epoch, batchsize)\n",
        "show_test_performance(classifier_model, test, batchsize)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch       main/loss   main/accuracy  val/main/loss  val/main/accuracy  elapsed_time\n",
            "\u001b[J1           1.57527     0.415011       1.24542        0.550435           21.6564       \n",
            "\u001b[J2           1.10432     0.604492       1.00444        0.64468            34.3525       \n",
            "\u001b[J3           0.886739    0.686452       0.878111       0.686412           47.0589       \n",
            "\u001b[J4           0.722546    0.744842       0.799431       0.719442           59.796        \n",
            "\u001b[J5           0.582985    0.791858       0.840015       0.723794           72.5094       \n",
            "\u001b[J6           0.459869    0.838592       0.826089       0.729134           85.2341       \n",
            "\u001b[J7           0.35312     0.873627       0.887507       0.733485           97.9174       \n",
            "\u001b[J8           0.253271    0.909981       0.992593       0.723991           110.676       \n",
            "\u001b[J9           0.1928      0.932408       1.01356        0.730617           123.416       \n",
            "\u001b[J10          0.150688    0.948217       1.14786        0.730419           136.127       \n",
            "\u001b[J11          0.130979    0.954498       1.31158        0.715783           148.849       \n",
            "\u001b[J12          0.109013    0.961538       1.32273        0.720728           161.528       \n",
            "\u001b[J13          0.0949301   0.967727       1.452          0.727848           174.254       \n",
            "\u001b[J14          0.0995826   0.965745       1.38578        0.729035           186.935       \n",
            "\u001b[J15          0.0774421   0.973792       1.50131        0.733683           199.664       \n",
            "\u001b[J16          0.0851238   0.971179       1.38442        0.722607           212.457       \n",
            "\u001b[J17          0.0739482   0.974566       1.62911        0.717366           225.205       \n",
            "\u001b[J18          0.0750772   0.974359       1.42204        0.726562           237.926       \n",
            "\u001b[J19          0.0696486   0.975789       1.72766        0.719442           250.647       \n",
            "\u001b[J20          0.0747984   0.973432       1.69812        0.722211           263.343       \n",
            "\u001b[J21          0.0664355   0.97831        1.63571        0.72409            276.104       \n",
            "\u001b[J22          0.0466884   0.984926       1.77108        0.730419           288.799       \n",
            "\u001b[J23          0.0524868   0.982503       1.65534        0.734078           301.501       \n",
            "\u001b[J24          0.0725335   0.975436       1.67318        0.719244           314.179       \n",
            "\u001b[J25          0.0634946   0.979832       1.7042         0.719739           326.887       \n",
            "\u001b[J26          0.0520155   0.982823       1.82314        0.723398           339.688       \n",
            "\u001b[J27          0.0550656   0.981779       1.79685        0.729134           352.406       \n",
            "\u001b[J28          0.0616643   0.978691       1.8701         0.73032            365.107       \n",
            "\u001b[J29          0.045667    0.984575       1.93116        0.713805           377.837       \n",
            "\u001b[J30          0.0525179   0.982447       1.75825        0.724782           390.522       \n",
            "\u001b[J31          0.0486423   0.9841         1.86123        0.734078           403.245       \n",
            "\u001b[J32          0.0508935   0.983298       1.8735         0.724288           415.969       \n",
            "\u001b[J33          0.0504027   0.983152       1.85638        0.729035           428.725       \n",
            "\u001b[J34          0.041418    0.986303       2.01897        0.722211           441.418       \n",
            "\u001b[J35          0.0434495   0.986297       1.94794        0.724486           454.181       \n",
            "\u001b[J36          0.0528532   0.983499       1.88093        0.721915           466.886       \n",
            "\u001b[J37          0.0541536   0.982328       1.95422        0.724585           479.633       \n",
            "\u001b[J38          0.0404589   0.986804       2.17359        0.717069           492.495       \n",
            "\u001b[J39          0.0526628   0.983152       2.14043        0.726266           505.212       \n",
            "\u001b[J40          0.0438713   0.986003       2.00012        0.735166           517.921       \n",
            "Test accuracy: 0.727057\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "X3NbbeiYbP0d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}