{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "GGu1q2S3Tpgf",
    "outputId": "7008c45f-e431-49c6-dfcd-0b83b7610bb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  1379  100  1379    0     0   8307      0 --:--:-- --:--:-- --:--:--  8307\n",
      "+ apt -y -q install cuda-libraries-dev-9-2\n",
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "cuda-libraries-dev-9-2 is already the newest version (9.2.148-1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 8 not upgraded.\n",
      "+ pip install -q cupy-cuda92  chainer \n",
      "+ set +ex\n",
      "Installation succeeded!\n",
      "Collecting chutil\n",
      "  Downloading https://files.pythonhosted.org/packages/74/d3/e761e43572a1bc53ab787a11b227b9ccc0e857cdb531805fb12e4e15707a/chutil-0.1.4-py3-none-any.whl\n",
      "Installing collected packages: chutil\n",
      "Successfully installed chutil-0.1.4\n"
     ]
    }
   ],
   "source": [
    "# import\n",
    "%matplotlib inline\n",
    "!curl https://colab.chainer.org/install | sh -\n",
    "!pip install chutil\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import chainer\n",
    "import chutil\n",
    "\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "from chainer import Chain\n",
    "import chainer.optimizers as optimizers\n",
    "\n",
    "from chainer.datasets.cifar import get_cifar100\n",
    "from chainer import optimizers, training\n",
    "from chainer.training import extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "91sKiB35Tpgm",
    "outputId": "7f980be0-9448-4d8c-bb90-329934dae5ec"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz...\n"
     ]
    }
   ],
   "source": [
    "# データセットがダウンロード済みでなければ、ダウンロードも行う\n",
    "train, test = get_cifar100()\n",
    "train, validation = chainer.datasets.split_dataset_random(train, 40000, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PrpX_Ir-Tpgo"
   },
   "outputs": [],
   "source": [
    "class MyConvNet(Chain):\n",
    "    def __init__(self):\n",
    "        super(MyConvNet, self).__init__()\n",
    "        with self.init_scope():\n",
    "            # 畳み込み層の定義\n",
    "            # in_channels:Noneを指定しても動的にメモリ確保するので問題なく動作する\n",
    "            # out_channels:出力する配列のチャンネル数\n",
    "            # ksize:フィルタのサイズ（平行移動するフィルターの長さを指定）\n",
    "            # stride:入力データに対してstride分フィルターを適用していくパラメータを指定\n",
    "            # pad:イメージは画像データの周りにpadのサイズ分だけ空白を用意してそこに対してもフィルターを適用するようなイメージ\n",
    "            # dilate:今回の実装では設定していないが、飛び飛びにフィルターを適用するパラメータ\n",
    "            self.conv1 = L.Convolution2D(\n",
    "                in_channels=None, out_channels=32, ksize=3, stride=1, pad=1)\n",
    "            # 畳み込み層の定義２層目\n",
    "            self.conv2 = L.Convolution2D(\n",
    "                in_channels=None, out_channels=64, ksize=3, stride=1, pad=1)\n",
    "            # 畳み込み層の定義３層目\n",
    "            self.conv3 = L.Convolution2D(\n",
    "                in_channels=None, out_channels=128, ksize=3, stride=1, pad=1)\n",
    "            self.conv4 = L.Convolution2D(\n",
    "                in_channels=None, out_channels=256, ksize=3, stride=1, pad=1)\n",
    "            self.conv5 = L.Convolution2D(\n",
    "                in_channels=None, out_channels=256, ksize=3, stride=1, pad=1)\n",
    "            self.fc6 = L.Linear(None, 1000)\n",
    "            self.fc7 = L.Linear(None, 100)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        h = F.relu(self.conv1(x.reshape((-1, 3, 32, 32))))\n",
    "        h = F.max_pooling_2d(h, ksize=2, stride=2)\n",
    "        h = F.relu(self.conv2(h))\n",
    "        h = F.max_pooling_2d(h, ksize=2, stride=2)\n",
    "        h = F.relu(self.conv3(h))\n",
    "        h = F.max_pooling_2d(h, ksize=2, stride=2)\n",
    "        h = F.relu(self.conv4(h))\n",
    "        h = F.relu(self.conv5(h))\n",
    "        h = F.relu(self.fc6(h))\n",
    "        return self.fc7(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yXUnZBvLTpgr"
   },
   "outputs": [],
   "source": [
    "def  train_and_validate(\n",
    "        model, optimizer, train, validation, n_epoch, batchsize, device=0):\n",
    "    \n",
    "    # 1. deviceがgpuであれば、gpuにモデルのデータを転送する\n",
    "    if device >= 0:\n",
    "        model.to_gpu(device)\n",
    "        \n",
    "    # 2. Optimizerを設定する\n",
    "    optimizer.setup(model)\n",
    "    \n",
    "    # 3. DatasetからIteratorを作成する\n",
    "    train_iter = chainer.iterators.SerialIterator(train, batchsize)\n",
    "    validation_iter = chainer.iterators.SerialIterator(\n",
    "        validation, batchsize, repeat=False, shuffle=False)\n",
    "    \n",
    "    # 4. Updater・Trainerを作成する\n",
    "    updater = training.StandardUpdater(train_iter, optimizer, device=device)\n",
    "    trainer = chainer.training.Trainer(updater, (n_epoch, 'epoch'), out='out')\n",
    "    \n",
    "    # 5. Trainerの機能を拡張する\n",
    "    trainer.extend(extensions.LogReport())\n",
    "    trainer.extend(extensions.Evaluator(validation_iter, model, device=device), name='val')\n",
    "    trainer.extend(extensions.PrintReport(\n",
    "        ['epoch', 'main/loss', 'main/accuracy', 'val/main/loss', 'val/main/accuracy', 'elapsed_time']))\n",
    "    trainer.extend(extensions.PlotReport(\n",
    "        ['main/loss', 'val/main/loss'],x_key='epoch', file_name='loss.png'))\n",
    "    trainer.extend(extensions.PlotReport(\n",
    "        ['main/accuracy', 'val/main/accuracy'], x_key='epoch', file_name='accuracy.png'))\n",
    "    trainer.extend(extensions.dump_graph('main/loss'))\n",
    "    \n",
    "    # 6. 訓練を開始する\n",
    "    trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0dsOxIWiTpgt"
   },
   "outputs": [],
   "source": [
    "# test 結果計算\n",
    "def show_test_performance(model, test, batchsize, device=0):\n",
    "    if device >= 0:\n",
    "        model.to_gpu()\n",
    "        \n",
    "    test_iter = chainer.iterators.SerialIterator(\n",
    "        test, batchsize, repeat=False, shuffle=False\n",
    "    )\n",
    "    test_evaluator = extensions.Evaluator(test_iter, model, device=device)\n",
    "    results = test_evaluator()\n",
    "    print(\"Test accuracy:\", results[\"main/accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 731
    },
    "colab_type": "code",
    "id": "N6YtkLtFTpgw",
    "outputId": "162ddfb1-4650-4afa-c50b-97de78e8d850"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch       main/loss   main/accuracy  val/main/loss  val/main/accuracy  elapsed_time\n",
      "\u001b[J1           4.06144     0.0731829      3.60926        0.13835            21.8792       \n",
      "\u001b[J2           3.24881     0.208934       3.08614        0.238331           35.0247       \n",
      "\u001b[J3           2.77216     0.296426       2.77612        0.303402           48.1662       \n",
      "\u001b[J4           2.4122      0.370393       2.65091        0.329213           61.2678       \n",
      "\u001b[J5           2.08473     0.439072       2.50608        0.355914           74.377        \n",
      "\u001b[J6           1.74294     0.51883        2.51225        0.370649           87.4692       \n",
      "\u001b[J7           1.37447     0.608626       2.68932        0.379055           100.541       \n",
      "\u001b[J8           1.00209     0.703726       2.88676        0.368374           113.672       \n",
      "\u001b[J9           0.672369    0.794753       3.31775        0.377077           126.779       \n",
      "\u001b[J10          0.427443    0.865485       3.81099        0.365012           139.878       \n",
      "\u001b[J11          0.293868    0.906699       4.19246        0.368473           152.96        \n",
      "\u001b[J12          0.209034    0.934245       4.7283         0.371143           165.994       \n",
      "\u001b[J13          0.186995    0.941244       4.98626        0.360265           179.049       \n",
      "\u001b[J14          0.180221    0.944712       5.11959        0.360463           192.069       \n",
      "\u001b[J15          0.153128    0.951378       5.42914        0.361551           205.127       \n",
      "\u001b[J16          0.144571    0.954127       5.42848        0.362243           218.229       \n",
      "\u001b[J17          0.134885    0.957019       5.76732        0.358188           231.314       \n",
      "\u001b[J18          0.143967    0.954527       5.89391        0.358881           244.348       \n",
      "\u001b[J19          0.137435    0.955871       5.75215        0.349387           257.448       \n",
      "\u001b[J20          0.133775    0.959034       5.92265        0.359968           270.506       \n",
      "\u001b[J21          0.128837    0.959964       6.39851        0.362342           283.602       \n",
      "\u001b[J22          0.119909    0.96269        6.40553        0.36254            296.659       \n",
      "\u001b[J23          0.126464    0.961312       6.33696        0.360759           309.708       \n",
      "\u001b[J24          0.100635    0.970277       6.17057        0.365012           322.703       \n",
      "\u001b[J25          0.126965    0.961387       6.31978        0.360364           335.766       \n",
      "\u001b[J26          0.119119    0.962665       6.98876        0.354035           348.785       \n",
      "\u001b[J27          0.11541     0.965181       6.76308        0.350178           361.945       \n",
      "\u001b[J28          0.0940259   0.970903       7.11259        0.355716           374.968       \n",
      "\u001b[J29          0.115888    0.964856       6.95373        0.355419           388.053       \n",
      "\u001b[J30          0.104657    0.967748       7.35806        0.355123           401.074       \n",
      "\u001b[J31          0.128136    0.961112       7.08144        0.347508           414.133       \n",
      "\u001b[J32          0.110252    0.966146       6.92089        0.351958           427.149       \n",
      "\u001b[J33          0.0811437   0.975639       7.2393         0.346717           440.19        \n",
      "\u001b[J34          0.107221    0.96855        7.65959        0.347805           453.211       \n",
      "\u001b[J35          0.101238    0.970223       7.58016        0.351167           466.288       \n",
      "\u001b[J36          0.102323    0.969251       7.72319        0.349189           479.324       \n",
      "\u001b[J37          0.115102    0.966229       7.74733        0.350277           492.388       \n",
      "\u001b[J38          0.101075    0.970403       8.28024        0.344937           505.437       \n",
      "\u001b[J39          0.097247    0.971995       7.93453        0.347805           518.643       \n",
      "\u001b[J40          0.0902967   0.972957       7.97217        0.347805           531.701       \n",
      "Test accuracy: 0.363034\n"
     ]
    }
   ],
   "source": [
    "n_epoch = 40\n",
    "batchsize = 128\n",
    "\n",
    "model = MyConvNet()\n",
    "classifier_model = L.Classifier(model)\n",
    "optimizer = optimizers.Adam()\n",
    "train_and_validate(\n",
    "    classifier_model, optimizer, train, validation, n_epoch, batchsize)\n",
    "show_test_performance(classifier_model, test, batchsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4AcSzjHETpgy"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "CNNByChainer_CIFAR100.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
