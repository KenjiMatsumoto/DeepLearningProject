{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNNByKeras_CIFAR100.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "code",
        "id": "jDkU4wvOP9MY",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import \n",
        "from keras.datasets import cifar100\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Model\n",
        "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, Dropout, Input, Dense, Flatten, BatchNormalization, Activation, add\n",
        "from keras.optimizers import Adam\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "import argparse\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "0-k5OsntP9Me",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# model作成 CNNByChainerと同じ層構成にする\n",
        "def create_CNN_model(input_shape=(32, 32, 3), class_num=100):\n",
        "    input = Input((32, 32, 3))\n",
        "    kernel_size = (3, 3)\n",
        "    max_pool_size = (2, 2)\n",
        "    # 畳み込み層の実装\n",
        "    # 1層目\n",
        "    cnn = Conv2D(64, kernel_size=kernel_size, padding='same', strides=(1, 1), activation='relu', input_shape=(32, 32, 3))(input)\n",
        "    cnn = MaxPooling2D(pool_size=max_pool_size, strides=(2, 2))(cnn)\n",
        "    cnn = Conv2D(128, kernel_size, padding='same', strides=(1, 1), activation='relu')(cnn)\n",
        "    cnn = MaxPooling2D(pool_size=max_pool_size, strides=(2, 2))(cnn)\n",
        "    cnn = Dropout(0.25)(cnn)\n",
        "    cnn = Conv2D(256, kernel_size, padding='same', strides=(1, 1), activation='relu')(cnn)\n",
        "    cnn = MaxPooling2D(pool_size=max_pool_size, strides=(2, 2))(cnn)\n",
        "    cnn = Conv2D(512, kernel_size, padding='same', strides=(1, 1), activation='relu')(cnn)\n",
        "    cnn = MaxPooling2D(pool_size=max_pool_size, strides=(2, 2))(cnn)\n",
        "    cnn = Dropout(0.25)(cnn)\n",
        "    cnn = Conv2D(512, kernel_size, padding='same', strides=(1, 1), activation='relu')(cnn)\n",
        "\n",
        "    # 入力を平滑化する層（いわゆるデータをフラット化する層、例えば4次元配列を1次元配列に変換するなど）\n",
        "    fc = Flatten()(cnn)\n",
        "    # denseは全結合層\n",
        "    fc = Dense(1000, activation='relu')(fc)\n",
        "    fc = Dropout(0.5)(fc)\n",
        "    softmax = Dense(100, activation='softmax')(fc)\n",
        "    model = Model(input=input, output=softmax)\n",
        "    \n",
        "    return model\n",
        " \n",
        "def rescell(data, filters, kernel_size, option=False):\n",
        "    strides=(1,1)\n",
        "    if option:\n",
        "        strides=(2,2)\n",
        "    x=Conv2D(filters=filters,kernel_size=kernel_size,strides=strides,padding=\"same\")(data)\n",
        "    x=BatchNormalization()(x)\n",
        "    x=Activation('relu')(x)\n",
        "    \n",
        "    data=Conv2D(filters=int(x.shape[3]), kernel_size=(1,1), strides=strides, padding=\"same\")(data)\n",
        "    x=Conv2D(filters=filters,kernel_size=kernel_size,strides=(1,1),padding=\"same\")(x)\n",
        "    x=BatchNormalization()(x)\n",
        "    x=add([x,data])\n",
        "    x=Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def ResNet(img_rows, img_cols, img_channels, x_train):\n",
        "\tinput=Input(shape=(img_rows,img_cols,img_channels))\n",
        "\tx=Conv2D(32,(7,7), padding=\"same\", input_shape=x_train.shape[1:],activation=\"relu\")(input)\n",
        "\tx=MaxPooling2D(pool_size=(2,2))(x)\n",
        "\n",
        "\tx=rescell(x,64,(3,3))\n",
        "\tx=rescell(x,64,(3,3))\n",
        "\tx=rescell(x,64,(3,3))\n",
        "\n",
        "\tx=rescell(x,128,(3,3),True)\n",
        "\n",
        "\tx=rescell(x,128,(3,3))\n",
        "\tx=rescell(x,128,(3,3))\n",
        "\tx=rescell(x,128,(3,3))\n",
        "\n",
        "\tx=rescell(x,256,(3,3),True)\n",
        "\n",
        "\tx=rescell(x,256,(3,3))\n",
        "\tx=rescell(x,256,(3,3))\n",
        "\tx=rescell(x,256,(3,3))\n",
        "\tx=rescell(x,256,(3,3))\n",
        "\tx=rescell(x,256,(3,3))\n",
        "\n",
        "\tx=rescell(x,512,(3,3),True)\n",
        "\n",
        "\tx=rescell(x,512,(3,3))\n",
        "\tx=rescell(x,512,(3,3))\n",
        "\n",
        "\tx=AveragePooling2D(pool_size=(int(x.shape[1]),int(x.shape[2])),strides=(2,2))(x)\n",
        "\n",
        "\tx=Flatten()(x)\n",
        "\tx=Dense(units=100,kernel_initializer=\"he_normal\",activation=\"softmax\")(x)\n",
        "\tmodel=Model(inputs=input,outputs=[x])\n",
        "\treturn model\n",
        "\n",
        "def train():\n",
        "\n",
        "    # cifar10のデータ取得\n",
        "    (x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
        "    x_train1, x_valid, y_train1, y_valid = train_test_split(x_train, y_train, test_size=0.2)\n",
        "    \n",
        "    model = ResNet(32,32,3,x_train)\n",
        "\n",
        "    # RGB画像で32×32なので32×32×3にreshapeする\n",
        "    x_train = x_train.reshape(x_train.shape[0], 32, 32, 3)\n",
        "    x_valid = x_valid.reshape(x_valid.shape[0], 32, 32, 3)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 32, 32, 3)\n",
        "    \n",
        "    x_train = x_train.astype('float32')\n",
        "    x_valid = x_valid.astype('float32')\n",
        "    x_test = x_test.astype('float32')\n",
        "    x_train /= 255\n",
        "    x_valid /= 255\n",
        "    x_test /= 255\n",
        "\n",
        "    # one-hot vector形式に変換する\n",
        "    y_train = to_categorical(y_train, 100)\n",
        "    y_valid = to_categorical(y_valid, 100)\n",
        "    y_test = to_categorical(y_test, 100)\n",
        "    \n",
        "    model.compile(loss=categorical_crossentropy,\n",
        "                  optimizer=Adam(),  metrics=['accuracy'])\n",
        "    # 学習\n",
        "    model.fit(x_train, y_train, epochs=40, batch_size=256, verbose=1, validation_data=(x_valid, y_valid))\n",
        "    # 精度算出\n",
        "    score = model.evaluate(x_test, y_test, verbose=0)\n",
        "    print('Test loss:', score[0])\n",
        "    print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "TVJ27ClIP9Mg",
        "outputId": "b43cde0a-f130-448c-adec-58bc4b7e3878",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "train()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/40\n",
            "50000/50000 [==============================] - 108s 2ms/step - loss: 4.4904 - acc: 0.0273 - val_loss: 4.8246 - val_acc: 0.0355\n",
            "Epoch 2/40\n",
            "40192/50000 [=======================>......] - ETA: 17s - loss: 3.8857 - acc: 0.0910"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "2wdCfZqbQEJf",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}