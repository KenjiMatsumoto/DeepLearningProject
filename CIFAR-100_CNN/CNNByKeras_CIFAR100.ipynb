{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNNByKeras_CIFAR100.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "code",
        "id": "jDkU4wvOP9MY",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import \n",
        "from keras.datasets import cifar100\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Model\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Input, Dense, Flatten, BatchNormalization, Activation\n",
        "from keras.optimizers import Adam\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "import argparse\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "0-k5OsntP9Me",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# model作成 CNNByChainerと同じ層構成にする\n",
        "def create_CNN_model(input_shape=(32, 32, 3), class_num=100):\n",
        "    input = Input((32, 32, 3))\n",
        "    kernel_size = (3, 3)\n",
        "    max_pool_size = (2, 2)\n",
        "    # 畳み込み層の実装\n",
        "    # 1層目\n",
        "    cnn = Conv2D(64, kernel_size=kernel_size, padding='same', strides=(1, 1), activation='relu', input_shape=(32, 32, 3))(input)\n",
        "    cnn = MaxPooling2D(pool_size=max_pool_size, strides=(2, 2))(cnn)\n",
        "    cnn = Conv2D(128, kernel_size, padding='same', strides=(1, 1), activation='relu')(cnn)\n",
        "    cnn = MaxPooling2D(pool_size=max_pool_size, strides=(2, 2))(cnn)\n",
        "    cnn = Dropout(0.25)(cnn)\n",
        "    cnn = Conv2D(256, kernel_size, padding='same', strides=(1, 1), activation='relu')(cnn)\n",
        "    cnn = MaxPooling2D(pool_size=max_pool_size, strides=(2, 2))(cnn)\n",
        "    cnn = Conv2D(512, kernel_size, padding='same', strides=(1, 1), activation='relu')(cnn)\n",
        "    cnn = MaxPooling2D(pool_size=max_pool_size, strides=(2, 2))(cnn)\n",
        "    cnn = Dropout(0.25)(cnn)\n",
        "    cnn = Conv2D(512, kernel_size, padding='same', strides=(1, 1), activation='relu')(cnn)\n",
        "\n",
        "    # 入力を平滑化する層（いわゆるデータをフラット化する層、例えば4次元配列を1次元配列に変換するなど）\n",
        "    fc = Flatten()(cnn)\n",
        "    # denseは全結合層\n",
        "    fc = Dense(1000, activation='relu')(fc)\n",
        "    fc = Dropout(0.5)(fc)\n",
        "    softmax = Dense(100, activation='softmax')(fc)\n",
        "    model = Model(input=input, output=softmax)\n",
        "    \n",
        "    return model\n",
        " \n",
        "def model_family_cnn(input_shape=(32, 32, 3), num_classes=100):\n",
        "    input_layer = Input(shape=input_shape)\n",
        "\n",
        "    # Block 1\n",
        "    conv1_1 = Conv2D(64, (3, 3),name='conv1_1', activation='relu', padding='same')(input_layer)\n",
        "    conv1_2 = Conv2D(64, (3, 3),name='conv1_2', activation='relu', padding='same')(conv1_1)\n",
        "    bn1 = BatchNormalization(axis=3)(conv1_2)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(bn1)\n",
        "    drop1 = Dropout(0.5)(pool1)\n",
        "\n",
        "    # Block 2\n",
        "    conv2_1 = Conv2D(128, (3, 3),name='conv2_1', activation='relu', padding='same')(drop1)\n",
        "    conv2_2 = Conv2D(128, (3, 3),name='conv2_2', activation='relu', padding='same')(conv2_1)\n",
        "    bn2 = BatchNormalization(axis=3)(conv2_2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(bn2)\n",
        "    drop2 = Dropout(0.5)(pool2)\n",
        "\n",
        "    # Block 3\n",
        "    conv3_1 = Conv2D(256, (3, 3),name='conv3_1', activation='relu', padding='same')(drop2)\n",
        "    conv3_2 = Conv2D(256, (3, 3),name='conv3_2', activation='relu', padding='same')(conv3_1)\n",
        "    conv3_3 = Conv2D(256, (3, 3),name='conv3_3', activation='relu', padding='same')(conv3_2)\n",
        "    conv3_4 = Conv2D(256, (3, 3),name='conv3_4', activation='relu', padding='same')(conv3_3)\n",
        "    bn3 = BatchNormalization(axis=3)(conv3_4)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(bn3)\n",
        "    drop3 = Dropout(0.5)(pool3)\n",
        "\n",
        "    # Block 4\n",
        "    conv4_1 = Conv2D(512, (3, 3),name='conv4_1', activation='relu', padding='same')(drop3)\n",
        "    conv4_2 = Conv2D(512, (3, 3),name='conv4_2', activation='relu', padding='same')(conv4_1)\n",
        "    conv4_3 = Conv2D(512, (3, 3),name='conv4_3', activation='relu', padding='same')(conv4_2)\n",
        "    conv4_4 = Conv2D(512, (3, 3),name='conv4_4', activation='relu', padding='same')(conv4_3)\n",
        "    bn4 = BatchNormalization(axis=3)(conv4_4)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(bn4)\n",
        "    drop4 = Dropout(0.5)(pool4)\n",
        "\n",
        "    # Block 5\n",
        "    conv5_1 = Conv2D(512, (3, 3),name='conv5_1', activation='relu', padding='same')(drop4)\n",
        "    conv5_2 = Conv2D(512, (3, 3),name='conv5_2', activation='relu', padding='same')(conv5_1)\n",
        "    conv5_3 = Conv2D(512, (3, 3),name='conv5_3', activation='relu', padding='same')(conv5_2)\n",
        "    conv5_4 = Conv2D(512, (3, 3),name='conv5_4', activation='relu', padding='same')(conv5_3)\n",
        "    bn5 = BatchNormalization(axis=3)(conv5_4)\n",
        "    pool5 = MaxPooling2D(pool_size=(2, 2))(bn5)\n",
        "    drop5 = Dropout(0.5)(pool5)\n",
        "    \n",
        "    x = Flatten()(drop5)\n",
        "    x = Dense(4096)(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(num_classes)(x)\n",
        "    x = Activation('softmax')(x)\n",
        "    model = Model(inputs=input_layer, outputs=x)\n",
        "    return model\n",
        "\n",
        "def train():\n",
        "\n",
        "    model = create_CNN_model()\n",
        "    # cifar10のデータ取得\n",
        "    (x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
        "    x_train1, x_valid, y_train1, y_valid = train_test_split(x_train, y_train, test_size=0.2)\n",
        "    # RGB画像で32×32なので32×32×3にreshapeする\n",
        "    x_train = x_train.reshape(x_train.shape[0], 32, 32, 3)\n",
        "    x_valid = x_valid.reshape(x_valid.shape[0], 32, 32, 3)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 32, 32, 3)\n",
        "    \n",
        "    x_train = x_train.astype('float32')\n",
        "    x_valid = x_valid.astype('float32')\n",
        "    x_test = x_test.astype('float32')\n",
        "    x_train /= 255\n",
        "    x_valid /= 255\n",
        "    x_test /= 255\n",
        "\n",
        "    # one-hot vector形式に変換する\n",
        "    y_train = to_categorical(y_train, 100)\n",
        "    y_valid = to_categorical(y_valid, 100)\n",
        "    y_test = to_categorical(y_test, 100)\n",
        "    \n",
        "    model.compile(loss=categorical_crossentropy,\n",
        "                  optimizer=Adam(),  metrics=['accuracy'])\n",
        "    # 学習\n",
        "    model.fit(x_train, y_train, epochs=40, batch_size=128, verbose=1, validation_data=(x_valid, y_valid))\n",
        "    # 精度算出\n",
        "    score = model.evaluate(x_test, y_test, verbose=0)\n",
        "    print('Test loss:', score[0])\n",
        "    print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "TVJ27ClIP9Mg",
        "outputId": "498189bd-e079-4111-f577-ca3f074512bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1445
        }
      },
      "cell_type": "code",
      "source": [
        "train()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/40\n",
            "50000/50000 [==============================] - 24s 472us/step - loss: 4.3217 - acc: 0.0329 - val_loss: 3.9655 - val_acc: 0.0682\n",
            "Epoch 2/40\n",
            "50000/50000 [==============================] - 22s 433us/step - loss: 3.7820 - acc: 0.1038 - val_loss: 3.4148 - val_acc: 0.1731\n",
            "Epoch 3/40\n",
            "50000/50000 [==============================] - 22s 436us/step - loss: 3.4173 - acc: 0.1701 - val_loss: 3.0982 - val_acc: 0.2355\n",
            "Epoch 4/40\n",
            "50000/50000 [==============================] - 22s 436us/step - loss: 3.1524 - acc: 0.2203 - val_loss: 2.8311 - val_acc: 0.2883\n",
            "Epoch 5/40\n",
            "50000/50000 [==============================] - 22s 435us/step - loss: 2.9238 - acc: 0.2654 - val_loss: 2.5136 - val_acc: 0.3489\n",
            "Epoch 6/40\n",
            "50000/50000 [==============================] - 22s 435us/step - loss: 2.7504 - acc: 0.3009 - val_loss: 2.3630 - val_acc: 0.3848\n",
            "Epoch 7/40\n",
            "50000/50000 [==============================] - 22s 434us/step - loss: 2.5957 - acc: 0.3320 - val_loss: 2.1740 - val_acc: 0.4244\n",
            "Epoch 8/40\n",
            "50000/50000 [==============================] - 22s 435us/step - loss: 2.4707 - acc: 0.3599 - val_loss: 2.0578 - val_acc: 0.4487\n",
            "Epoch 9/40\n",
            "50000/50000 [==============================] - 22s 437us/step - loss: 2.3399 - acc: 0.3843 - val_loss: 1.9132 - val_acc: 0.4835\n",
            "Epoch 10/40\n",
            "50000/50000 [==============================] - 22s 436us/step - loss: 2.2406 - acc: 0.4066 - val_loss: 1.7818 - val_acc: 0.5192\n",
            "Epoch 11/40\n",
            "50000/50000 [==============================] - 22s 436us/step - loss: 2.1376 - acc: 0.4254 - val_loss: 1.6480 - val_acc: 0.5483\n",
            "Epoch 12/40\n",
            "50000/50000 [==============================] - 22s 433us/step - loss: 2.0559 - acc: 0.4449 - val_loss: 1.5684 - val_acc: 0.5723\n",
            "Epoch 13/40\n",
            "50000/50000 [==============================] - 22s 436us/step - loss: 1.9656 - acc: 0.4637 - val_loss: 1.4897 - val_acc: 0.5847\n",
            "Epoch 14/40\n",
            "50000/50000 [==============================] - 22s 435us/step - loss: 1.8982 - acc: 0.4807 - val_loss: 1.4129 - val_acc: 0.6070\n",
            "Epoch 15/40\n",
            "50000/50000 [==============================] - 22s 435us/step - loss: 1.8287 - acc: 0.4950 - val_loss: 1.2531 - val_acc: 0.6561\n",
            "Epoch 16/40\n",
            "50000/50000 [==============================] - 22s 435us/step - loss: 1.7702 - acc: 0.5109 - val_loss: 1.1922 - val_acc: 0.6671\n",
            "Epoch 17/40\n",
            "50000/50000 [==============================] - 22s 434us/step - loss: 1.7107 - acc: 0.5256 - val_loss: 1.1261 - val_acc: 0.6831\n",
            "Epoch 18/40\n",
            "50000/50000 [==============================] - 22s 435us/step - loss: 1.6576 - acc: 0.5359 - val_loss: 1.0753 - val_acc: 0.7020\n",
            "Epoch 19/40\n",
            "50000/50000 [==============================] - 22s 435us/step - loss: 1.6011 - acc: 0.5505 - val_loss: 1.0497 - val_acc: 0.7054\n",
            "Epoch 20/40\n",
            "50000/50000 [==============================] - 22s 436us/step - loss: 1.5366 - acc: 0.5653 - val_loss: 0.9496 - val_acc: 0.7287\n",
            "Epoch 21/40\n",
            "50000/50000 [==============================] - 22s 434us/step - loss: 1.5093 - acc: 0.5716 - val_loss: 0.8587 - val_acc: 0.7604\n",
            "Epoch 22/40\n",
            "50000/50000 [==============================] - 22s 434us/step - loss: 1.4504 - acc: 0.5827 - val_loss: 0.8319 - val_acc: 0.7677\n",
            "Epoch 23/40\n",
            "50000/50000 [==============================] - 22s 435us/step - loss: 1.4150 - acc: 0.5920 - val_loss: 0.7931 - val_acc: 0.7822\n",
            "Epoch 24/40\n",
            "50000/50000 [==============================] - 22s 436us/step - loss: 1.3980 - acc: 0.5965 - val_loss: 0.7334 - val_acc: 0.7974\n",
            "Epoch 25/40\n",
            "50000/50000 [==============================] - 22s 437us/step - loss: 1.3370 - acc: 0.6110 - val_loss: 0.6860 - val_acc: 0.8095\n",
            "Epoch 26/40\n",
            "50000/50000 [==============================] - 22s 435us/step - loss: 1.3018 - acc: 0.6189 - val_loss: 0.6407 - val_acc: 0.8313\n",
            "Epoch 27/40\n",
            "50000/50000 [==============================] - 22s 435us/step - loss: 1.2778 - acc: 0.6279 - val_loss: 0.6379 - val_acc: 0.8246\n",
            "Epoch 28/40\n",
            "50000/50000 [==============================] - 22s 435us/step - loss: 1.2408 - acc: 0.6411 - val_loss: 0.5920 - val_acc: 0.8419\n",
            "Epoch 29/40\n",
            "50000/50000 [==============================] - 22s 437us/step - loss: 1.2111 - acc: 0.6468 - val_loss: 0.5335 - val_acc: 0.8588\n",
            "Epoch 30/40\n",
            "50000/50000 [==============================] - 22s 435us/step - loss: 1.1901 - acc: 0.6493 - val_loss: 0.5192 - val_acc: 0.8576\n",
            "Epoch 31/40\n",
            "50000/50000 [==============================] - 22s 436us/step - loss: 1.1621 - acc: 0.6594 - val_loss: 0.5480 - val_acc: 0.8508\n",
            "Epoch 32/40\n",
            "50000/50000 [==============================] - 22s 435us/step - loss: 1.1378 - acc: 0.6655 - val_loss: 0.4476 - val_acc: 0.8848\n",
            "Epoch 33/40\n",
            "50000/50000 [==============================] - 22s 435us/step - loss: 1.1019 - acc: 0.6764 - val_loss: 0.4105 - val_acc: 0.8929\n",
            "Epoch 34/40\n",
            "50000/50000 [==============================] - 22s 436us/step - loss: 1.0972 - acc: 0.6749 - val_loss: 0.4053 - val_acc: 0.8911\n",
            "Epoch 35/40\n",
            "50000/50000 [==============================] - 22s 436us/step - loss: 1.0723 - acc: 0.6819 - val_loss: 0.3981 - val_acc: 0.8925\n",
            "Epoch 36/40\n",
            "50000/50000 [==============================] - 22s 434us/step - loss: 1.0555 - acc: 0.6861 - val_loss: 0.3559 - val_acc: 0.9125\n",
            "Epoch 37/40\n",
            "50000/50000 [==============================] - 22s 436us/step - loss: 1.0245 - acc: 0.6963 - val_loss: 0.3563 - val_acc: 0.9102\n",
            "Epoch 38/40\n",
            "50000/50000 [==============================] - 22s 434us/step - loss: 1.0053 - acc: 0.7036 - val_loss: 0.3196 - val_acc: 0.9187\n",
            "Epoch 39/40\n",
            "50000/50000 [==============================] - 22s 436us/step - loss: 0.9934 - acc: 0.7046 - val_loss: 0.3095 - val_acc: 0.9221\n",
            "Epoch 40/40\n",
            "50000/50000 [==============================] - 22s 434us/step - loss: 0.9790 - acc: 0.7079 - val_loss: 0.3914 - val_acc: 0.8953\n",
            "Test loss: 2.6291591659545896\n",
            "Test accuracy: 0.4431\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "2wdCfZqbQEJf",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}