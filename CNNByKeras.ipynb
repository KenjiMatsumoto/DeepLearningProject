{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ySgemeTB7H_T"
   },
   "outputs": [],
   "source": [
    "# import \n",
    "from keras.datasets import mnist\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Input, Dense, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.utils import to_categorical\n",
    "import argparse\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4ZvLjJNE7H_X"
   },
   "outputs": [],
   "source": [
    "# model作成 CNNByChainerと同じ層構成にする\n",
    "def create_CNN_model(input_shape=(28, 28, 1), class_num=10):\n",
    "    input = Input((28, 28, 1))\n",
    "    kernel_size = (3, 3)\n",
    "    max_pool_size = (2, 2)\n",
    "    # 畳み込み層の実装\n",
    "    # 1層目\n",
    "    cnn = Conv2D(32, kernel_size=kernel_size, padding='same', activation='sigmoid', input_shape=(28, 28, 1))(input)\n",
    "    cnn = MaxPooling2D(pool_size=max_pool_size, strides=(1, 1))(cnn)\n",
    "    cnn = Conv2D(64, kernel_size, padding='same', activation='sigmoid')(cnn)\n",
    "    cnn = MaxPooling2D(pool_size=max_pool_size, strides=(1, 1))(cnn)\n",
    "    cnn = Conv2D(128, kernel_size, padding='same', activation='sigmoid')(cnn)\n",
    "    cnn = MaxPooling2D(pool_size=max_pool_size, strides=(1, 1))(cnn)\n",
    "    cnn = Conv2D(128, kernel_size, padding='same', activation='sigmoid')(cnn)\n",
    "    # 入力を平滑化する層（いわゆるデータをフラット化する層、例えば4次元配列を1次元配列に変換するなど）\n",
    "    fc = Flatten()(cnn)\n",
    "    # denseは全結合層\n",
    "    fc = Dense(1000, activation='sigmoid')(fc)\n",
    "    softmax = Dense(10, activation='softmax')(fc)\n",
    "    model = Model(input=input, output=softmax)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# 全体の正解率を算出\n",
    "def predict_accuracy(x_batch, y_batch, model):\n",
    "    # 予測確率\n",
    "    preds = model.predict(x_batch, verbose=0)\n",
    "    batch_size = len(x_batch)\n",
    "    count = 0\n",
    "    # y(正解の値)とpred(予測の値)を比較\n",
    "    for (y, pred) in zip(y_batch, preds):\n",
    "        # 正解かどうかをチェックし、正解した場合カウントする\n",
    "        if np.argmax(y) == np.argmax(pred):\n",
    "            count += 1\n",
    "    print('acc ', (count/batch_size))\n",
    "\n",
    "def train():\n",
    "\n",
    "    model = create_CNN_model()\n",
    "    # mnistデータの取得\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    x_train1, x_valid, y_train1, y_valid = train_test_split(x_train, y_train, test_size=0.175)\n",
    "    # グレースケールの画像で28×28なので28×28×1にreshapeする\n",
    "    x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "    x_valid = x_valid.reshape(x_valid.shape[0], 28, 28, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "    \n",
    "    x_train = x_train.astype('float32')\n",
    "    x_valid = x_valid.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_train /= 255\n",
    "    x_valid /= 255\n",
    "    x_test /= 255\n",
    "\n",
    "    # one-hot vector形式に変換する\n",
    "    y_train = to_categorical(y_train, 10)\n",
    "    y_valid = to_categorical(y_valid, 10)\n",
    "    y_test = to_categorical(y_test, 10)\n",
    "    \n",
    "    model.compile(loss=categorical_crossentropy,\n",
    "                  optimizer=Adam())\n",
    "    print(y_train.shape)\n",
    "    # 学習\n",
    "    model.fit(x_train, y_train, epochs=20, batch_size=128, verbose=1, validation_data=(x_valid, y_valid))\n",
    "    # 精度算出\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "#     predict_accuracy(x_test, y_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 748
    },
    "colab_type": "code",
    "id": "K3CL3NQw7H_Z",
    "outputId": "4adbe818-18fe-4609-f7a3-f0a124ccb836"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kokubun/.pyenv/versions/3.6.2/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py:20: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n",
      "Train on 60000 samples, validate on 10500 samples\n",
      "Epoch 1/20\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WodkuBOz7H_e"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "CNNByKeras.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
